## 定义
决策树是一种逼近离散值目标函数的方法
![输入图片说明](/imgs/2025-11-20/nYKoMgavlt6QXj69.png)
## 适用范围
实例是<属性，值>对
目标函数有离散的输出
可能需要析取的描述
可能包含错误的训练集
包含缺少属性的实例的训练集
适用于分类问题，将实例识别为离散的可能
## 核心算法：ID3
ID3算法通过自顶向下构造决策树学习，利用了贪婪搜索遍历可能的决策树空间
![输入图片说明](/imgs/2025-11-20/UP2DJDgIopDRdrc1.png)
## 信息熵与信息增益
ID3算法的核心之一是要判断出哪个属性是（当前）最佳的分类属性，用信息熵和信息增益衡量
信息熵刻画了样例集的纯度（对S中任意成员类别编码所需的最小位数），信息增益度量某个属性的分类能力
![输入图片说明](/imgs/2025-11-20/8eOGpoK0JtW2x7Nb.png)
![输入图片说明](/imgs/2025-11-20/KFwLobzr23Avbq8l.png)
## 决策树学习的假设空间搜索
ID3的优势：避免了搜索不完整的假设空间，避免了假设空间可能不包含目标函数的情况。同时对样例错误的敏感性低，易扩展到处理含有噪声的训练数据
不足：ID3仅维护单一的当前假设，不能判断有多少其他决策树和现有数据一致。基本ID3算法不回溯，容易收敛到局部最优
## 决策树的归纳偏置
ID3一般从决策树中选择：1.较短的树 2.信息增益高的属性离根节点较近的树
![输入图片说明](/imgs/2025-11-20/wonzBOP3thzpdIoz.png)
ID3的归纳偏置是对某种假设胜过其他假设的一种优选，对最终可列举的假设没有硬性吸纳之，称为优选偏置
候选消除算法的偏置是对待考虑假设的一种限定，称之为限定偏置
通常优选偏置比限定偏置更符合泛化的需要，它允许学习器工作在完整的假设空间上。
## 过拟合
![输入图片说明](/imgs/2025-11-20/RTSOb4oMoLZAACAC.png)
训练集中的随机噪声、少数实例和叶节点的关联性都可能导致过拟合
可以通过及时停止对树的增长和后修剪法，即允许树过拟合，然后再对树进行修剪来防止过拟合
修剪方法：
错误率降低修剪：删除以该节点为根的子树，使其变为叶节点，指定类别为最常见的训练样例的类别，如果修剪后的性能不比原来的差，则重复直到修剪有害
规则后修剪：对于过拟合的决策树，将每个从根到叶子的路径创建一条规则，删除可以提高规则估计精度的前件，对xiu'j
## 例题 · playtennis
![输入图片说明](/imgs/2025-11-20/jlvhj8CX7wGq395P.png)
![输入图片说明](/imgs/2025-11-20/HTjM0zom9TJHoWW2.png)
![输入图片说明](/imgs/2025-11-20/AsHU0FmpAYVyYuCr.png)
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTExNTEyMDk2MjQsMTM3MDc0NDIxMiw3Mj
k0MjM5NzYsNzg5NDIxOTQsLTE3MTM1NDkwMiw3Mzg2NzI3Njcs
LTIwODg3NDY2MTJdfQ==
-->