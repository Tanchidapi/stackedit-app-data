## 贝叶斯公式
概率论中的基础，提供了从先验概率及其他给出的条件下计算后验概率的方法
![输入图片说明](/imgs/2025-11-21/1kzzZei4ubfkKvhx.png)
贝叶斯法则是在机器学习的任务中，根据观察到的训练集数据D，找出最佳假设，最佳假设是指在给定数据和各种假设的先验概率下，最可能成立的假设
![输入图片说明](/imgs/2025-11-21/0OEHUaLgTXwj5XTt.png)
![输入图片说明](/imgs/2025-11-21/fazlZiTCZDknIofu.png)
需注意的是，极大后验假设和极大似然假设的区别，极大似然假设是最简单的一种情况
上述公式假定了所有假设概率先验概率一致，即所有假设是平等的
![输入图片说明](/imgs/2025-11-21/uBPO58mFfe0z0ebs.png)
## 贝叶斯法则和概念学习
Brute-Force贝叶斯概念学习
![输入图片说明](/imgs/2025-11-21/M6PZskreovVove9g.png)
此算法需要较大的计算量假设空间较大时不切实际
上述算法需要以下前提
![输入图片说明](/imgs/2025-11-21/4HOE5olVchpzwrrW.png)
则有，对于算法学习中
![输入图片说明](/imgs/2025-11-21/OptMqZlOqeXr4gtU.png)
则对于概念学习
![输入图片说明](/imgs/2025-11-21/SAt7Pxq5TQxznnnZ.png)
因此，概念学习中，每一个一致的假设都是MAP假设
## 一致学习器
某学习算法被称为一致学习器，说明其输出的假设在训练样例上有零错误率。即如果假设空间中有均匀的先验概率，且训练数据确定、无噪声，则任意一致学习器将输出一个MAP假设
Find-S算法输出极大特殊假设，因此如果先验概率更偏袒于更特殊假设，Find-S仍能输出MAP假设
以贝叶斯方法刻画学习算法，和揭示学习器中的归纳偏置是类似的。
## 极大似然和最小误差平方假设
在特定前提下，任一学习算法如果使输出的假设预测和训练数据之间的误差平方最小化，它将输出一极大似然假设
前提是训练集的目标值被随机样例干扰，随机噪声服从正态分布
因为我们需要令随机变量所有可能值的和为1，但变量是连续的，因此以概率密度定义在某一点上的概率
![输入图片说明](/imgs/2025-11-21/LaZmneWWhasQ4syx.png)
有了上述两个概念，就可以说明最小误差平方假设就是极大似然假设
![输入图片说明](/imgs/2025-11-21/UhDOXnMnvXcB1e1y.png)
假定噪声正态分布的原因有以下几点：一是计算的简洁，二是其对实际噪声有良好的近似，三是中心极限定理显示足够多的独立同分布随机变量的和服从正态分布
## 预测概率的极大似然假设

## 例题 · 病人患癌的概率
![输入图片说明](/imgs/2025-11-21/QDmBqcCp3sE6gWST.png)
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTE1MzA0MjYwMSwxMzgyNTgzNTAwLC0yOD
MwNjAxMTgsLTE1Mzg3OTU4MDQsLTE5OTQ0OTU2MTUsMzg5MDcz
MjA3LDE3Nzk0NzE1OTUsLTQwNDY5ODU4MSwxNzM2ODM0NjIyLC
00MjI1NTA3MDYsLTIwODg3NDY2MTJdfQ==
-->