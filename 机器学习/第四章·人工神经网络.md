## BP神经网络
一个有向图，可能有环
学习是为图中每条边选取一个权值
适用具有以下特征的问题：
实例由许多属性-值对表示(结构化数据)
向量描述实例，高维
也适用非结构化数据（深度学习）
目标函数:离散值函数、实值函数或向量函数
训练数据可能包含错误
有噪声的、复杂的传感器数据(摄像头、麦克风)
## 感知器
感知器以一个实数值向量作为输入，计算输入的线性组合，如果结果大于某个阈值，则输出1，否则为-1
![输入图片说明](/imgs/2025-11-20/rkRt22QP2VgcAM0O.png)
![输入图片说明](/imgs/2025-11-20/XjrM1QauRYNX7krf.png)
感知器可以看作是n维实例空间的一个超决策平面，将正反例分为平面两端
![输入图片说明](/imgs/2025-11-20/ndShvkjW0E2FkePA.png)
两层的感知器网络就可以表示所有的布尔函数
## 感知器学习算法
1.感知器法则：
从随机的权值开始，反复应用整个感知器到每一个训练样例，误分类时修改权值
![输入图片说明](/imgs/2025-11-20/OY4KW97bdeyxIf6w.png)
上述法则在数据线性可分并且η足够小的情况下可以保证训练收敛
2.梯度下降和delta法则：
克服了感知器规则的不足，对于非线性可分的数据，该法则可以收敛到目标概念的最佳近似
关键方法是使用梯度下降法搜索H，找到最适合实例的权值
可以将delta训练法则理解为训练一个无阈值的感知器，也就是一个线性单元
训练误差定义为
![输入图片说明](/imgs/2025-11-20/xVfXkiFU4hCBNkN4.png)
利用梯度运算
![输入图片说明](/imgs/2025-11-20/4CF1e2sWx419wP1Y.png)
![输入图片说明](/imgs/2025-11-20/4Loe9VrGiNNQqdyC.png)
计算偏导得到
![输入图片说明](/imgs/2025-11-20/EjFno7xyhKcu3VDN.png)
算法如下
![输入图片说明](/imgs/2025-11-20/apYGWJTDWv0p9nOt.png)
梯度下降的问题在于收敛可能很慢，并且不保证找到全局最小误差的权值
解决这些问题的一个常见变体为增量/随机梯度下降
随机梯度和标准梯度的关键区别在于标准是在权值更新前对所有样例汇总误差，而随机是通过考查每个训练样例来更新的，同时随机的步长和计算量更小，更可能避免陷入局部极小值
Delta也可以用来训练阈值感知器单元
如果无阈值输出o可以完美拟合目标值，那么阈值输出o '也会拟合目标值
即使目标值不能完美匹配，只要线性单元输出o与目标值符号一致，阈值o '值也能正确匹配目标值
Delta法则使线性单元学习到具有输出误差最小的权重，这些权重不一定会使阈值单元输出误差最小。
## 多层网络和反向传播算法
要求能表示高度非线性的函数，且适用于梯度下降算法（可微分）

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE1OTU3NzgzNzIsODk0NzkzOTUyLDgyMz
U5MTcyNiwtNDU3NDA0MzIzLC05MDQ5NzMxNzMsMTk4MzY4MTgz
OF19
-->