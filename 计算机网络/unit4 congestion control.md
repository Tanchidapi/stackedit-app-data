## 拥塞基本定义
### 拥塞的情况
![输入图片说明](/imgs/2025-09-18/BBudinJn2s2Lz8Eg.png)总结
拥塞是不可避免的，流量控制是解决拥塞的关键
### 公平性有利于设计拥塞控制
![输入图片说明](/imgs/2025-09-18/Dphl7bM1AsV9ma65.png)示意图

方案一保证了吞吐量，但是方案二在第二条链路上保证了公平性，设计拥塞时要提前达成公平性

![输入图片说明](/imgs/2025-09-18/7uSqvVPRANRCjw1L.png)常用的公平方法——最大最小原则

简单来说就是将最大流最小化，即不能通过减小一个小流的速率来增大一个比他大的流的速率，本质上为共享一个链路的瓶颈，上述情况的方案二就是在最大最小原则下的速率分配情况

![输入图片说明](/imgs/2025-09-18/oyHfz87EVB0Hbnda.png)以单链路为例的一个分配例子

先根据输入链路数量与输出链路速率平均分配，然后从速率最小的输入链路开始，如果其速率小于分配速率，则只分配给其对应的速率，剩下的速率再平分给剩下的链路，然后再考虑次小，如果超过了分配的速率，则只分配给其平均速率，以此类推

### 阻塞控制的目标
1. 实现高吞吐量
2. 实现公平性，通过最大最小原则实现
3. 实现对网络情况的快速反应
4. 实现分布式控制

## 拥塞控制基本方法

### 基于网络的流量控制
需要注意的一点是之前提到过的（加权）公平队列确实可以控制每个链路对应的发送速率，但是不能反馈到输入链路的源以控制他们该以什么速率来发送数据，因此实现拥塞控制时需要来自路由器的显示反馈用于指示网络中的拥塞。通常可以将网络中拥塞的情况如输出链路的剩余流量大小、丢包情况等，通过搭乘要到达某一端点的包来反馈到该端点，端主机可以自由的决定如何处理网络中存在拥塞的情况，如减小流量、实行最大最小公平性等
![输入图片说明](/imgs/2025-09-18/lXjFm32AtS0C8wXv.png)示意图

### 基于端主机的流量控制
设想为通过观察网络的行为，由此来决定发送数据的速率。这一方法的优势在于如果不依赖于路由器的行为，或者不依赖于路由器发送回特定的消息，则端主机可以在不更改网络的情况下随着时间的推移而演化和适应它。一个实际的例子就是TCP，它通过观察网路的行为，完全在端主机上实现拥塞控制。如果一个包丢失了，则端主机可以通过超时或者看到一系列相同的确认信息来判断，从而减小速率来控制拥塞。TCP之所以采取这种方式的还有一个原因是IP本身不提供网络中拥塞情况的反馈，TCP是在IP基础上的，因此采用基于端主机的方式来进行流量控制

![输入图片说明](/imgs/2025-09-18/sQSkXkcJpX3SqLwg.png)示意图

![输入图片说明](/imgs/2025-09-18/OxrrvuNpKxUVhk4h.png)TCP控制概述

![输入图片说明](/imgs/2025-09-18/wy0c0UGYraJvSKSx.png)图中展示的两种情况，一是往返时间大于窗口大小的情况，二是往返时间等于窗口大小的情况，第二种情况下对网络的利用效率更高

![输入图片说明](/imgs/2025-09-18/3Wa5R2qx5uRBgnEj.png)TCP协议会在发送方考虑滑动窗口的大小，在网络通畅时，会用接收端反馈的窗口大小，而在网络拥塞时，则会在发送端计算cwnd的大小，将其作为窗口大小

![输入图片说明](/imgs/2025-09-18/FlVfQjMPgAzpcyKv.png)计算cwnd的方法为AIMD，即线性增大、乘性减小，每有一个包顺利收到则cwnd大小增加窗口大小的倒数，否则若丢包则将窗口大小减半，因此若一窗口顺利发送则会为窗口增加1的大小（W个包），否则就将窗口大小减半。下图是示意图，这一曲线也被称作TCP（AIMD）锯齿波，绿色的曲线是放大后的图像，实际上是每过一个RTT（包确认往返时间）cwnd才增大1

![输入图片说明](/imgs/2025-09-18/THvsV0IXLn0onPA5.png)Summary

## 单数据流中的AIMD控制
![输入图片说明](/imgs/2025-09-18/kCrWW4HVDh242WGQ.png)示意图
在缓冲区放不下输入链路来的数据包后，会出现丢包，并将该标记附加在缓冲区队列中的最后一个包，等该包到达目的地后目的地会返回丢包信号，发送端收到该信号后就会按照AIMD减小一半的窗口大小，同时停止发送，停止发送与恢复的情况如下图

![输入图片说明](/imgs/2025-09-18/RzpOVbn3pXKLVoch.png)两种方法发送端来判断是否丢包，并做出不同的处理

![输入图片说明](/imgs/2025-09-18/pGflQrtdiZ6vovu5.png)示意图三张图有四张曲线，分别表示了cwnd的大小、往返时间（由于有包在缓冲区中而变大）、瓶颈链路利用率、缓冲区占用率
由图可以看出在AIMD的作用下链路始终保持繁忙，提高了利用效率

![输入图片说明](/imgs/2025-09-18/2CmyEISRX8kOFyGa.png)单流下的速率计算，可以简单的定义为一个窗口所发送出的字节数除以往返时间，因此其实最终结果是一个常数，窗口本质上做的就是探索袋子有多大，我们可以将多少字节放入网络而不溢出

![输入图片说明](/imgs/2025-09-18/TZgmALuVWJGJFbct.png)关于缓冲区的大小，最理想的情况是其大小等于往返时间乘上链路输出的速率，如果小于该大小，则会导致在发生减半后的一小段时间内链路的利用率降低

### 示例
![输入图片说明](/imgs/2025-09-18/WrlvUS8S7f09mB2M.png)![输入图片说明](/imgs/2025-09-18/GMQHddXR58P1pA4S.png)![输入图片说明](/imgs/2025-09-18/E6hKEnx1cyOn3UoO.png)![输入图片说明](/imgs/2025-09-18/vW35pxbeFdIC3Rzz.png)![输入图片说明](/imgs/2025-09-18/8UzY5VPi5fg3Y9ub.png)![输入图片说明](/imgs/2025-09-18/mesBl1QlcW74Vg2I.png)最后一题的答案提示了我们在出现丢包后AIMD需要长时间来恢复到缓冲区的最大利用率的情况，因此还需对此方法做出修改
## 多流数据下的AIMD控制
AIMD并不是控制发送速率，实际上，AIMD控制的是网络中未确认数据包的数量，即那些已发出但还没收到确认的数据包，当网络为空且没有阻塞时，它有空间让一个流发送更多的包，并在网络中拥有更多未确认包，但当网络发生拥塞、充满了数据包时，我们必须减少流中未确认数据包的数量以防止溢出

![输入图片说明](/imgs/2025-09-20/qCEMWi56ZFCiGS7O.png)多流情况下，缓冲区里的数据包来自各个流

![输入图片说明](/imgs/2025-09-20/Th6n43U5wfeKVnI7.png)
当存在多个流时，将RTT（往返时间）视为基本恒定的想法是合理的，因为多流下的缓冲区几乎总是拥塞的，但是单流情况下RTT会随着缓冲区的情况而变化，因此其锯齿波在上升时呈现一定弧度，每一个窗口的完整发送所用的往返时间随着缓冲区内包的增多而变大，因此计算多流下的平均吞吐率可以用平均窗口大小除以RTT

![输入图片说明](/imgs/2025-09-20/cCfv5wq1Xg4ZYeBy.png)吞吐率与丢包概率的关系，以几何的形式推导，注意图中阴影面积的A指的是在一个周期内发送的总的字节数，是发送的窗口个数对各个窗口大小的一个累积，故A的表达式中不含RTT项，最终将速率写成和丢包概率有关的函数，RTT为已知量

![输入图片说明](/imgs/2025-09-20/OdQqEPfS9l4lOhBe.png)第一点含义为在AIMD下我们会惩罚更远的链路速率，但这不是我们想要的，因此这一点通常被认为是AIMD的缺点
第二点指出了丢包是AIMD中控制的关键，它告诉发送方网络中存在太多未确认的包，从而指导发送方控制窗口大小，进而控制拥塞

![输入图片说明](/imgs/2025-09-20/gObFQOzFVvMioC7E.png)Summary

## TCP Tahoe
### 旧的TCP方案
![输入图片说明](/imgs/2025-09-20/Ec2W2NqqprenZDVa.png)在流量控制出现前，TCP总是直接将可用窗口大小的数据量一次性发送，即发送方在建立连接后，会一口气将接收方声明窗口大小的数据包全部注入网络中，这种方法被称为流量启动

![输入图片说明](/imgs/2025-09-20/t0gfTwulSgf9yeg6.png)早期没有拥塞控制下的TCP，因大量的丢包或超时的重传而导致没有预期中的吞吐率

![输入图片说明](/imgs/2025-09-20/eOi7hSod6d6YDZrS.png)三个改进方案分别为拥塞窗口控制，更好的超时估计和自时钟

### 拥塞窗口控制
前文提到的AIMD就是拥塞窗口控制的一个基本思想

![输入图片说明](/imgs/2025-09-20/sghH86HPANxauX7f.png)控制窗口只取决于端主机，大小为流量窗口与拥塞窗口中的最小值，因为在网络有限的情况下超越网络流量窗口大小发送接收方不一定接受的了，而拥塞的情况下发出再大的包也无意义，而拥塞窗口的大小可以分为两种情况：
1. 慢启动，用于重连和数据包超时的情况
2. 拥塞避免，用于接近网络容量拥塞时使用
### 慢启动
慢启动的慢其实是相对于旧版TCP的流量启动而言的，事实上，慢启动的总体过程中，发送数据包的大小与时间呈指数关系，并不慢
慢启动是一种试探性增长的过程，一开始，将窗口大小的起点设置为一个较小的值，每收到一个ack窗口才增加一个MSS

![输入图片说明](/imgs/2025-09-21/BuDhjaWUVrxFNb08.png)慢启动的好处
### 拥塞避免
![输入图片说明](/imgs/2025-09-21/YPbrjuAHr9sL5sWJ.png)拥塞避免与慢启动的区别，拥塞避免是在每收到一个ack确认，发送窗口就增加MSS平方除以拥塞窗口大小的大小，实际上是随着往返时间RTT的一个线性增长

### 两种状态的切换
![输入图片说明](/imgs/2025-09-21/RD4G2HCo3HLjCzyV.png)慢启动和拥塞避免两种状态的切换情况

![输入图片说明](/imgs/2025-09-21/QETey1xyrZ3C2B7h.png)TCP Tahoe的有限状态机，在慢启动和拥塞避免之间切换状态，ssthresh为慢启动的阈值，慢启动在窗口大小指数增长到阈值后切换到拥塞避免，然后变为线性增长，在出现超时或者三次重复的ack出现后将cwnd降至1，并将ssthresh改为原先cwnd大小的一半，再次开始慢启动

![输入图片说明](/imgs/2025-09-21/CvCxngXeTVzK8qB1.png)示意图

### 更准确的RTT估计
![输入图片说明](/imgs/2025-09-21/dpLCwrGNHvPTlWTK.png)RTT估计的重要性

![输入图片说明](/imgs/2025-09-21/3MgcRZB89T3v9VQc.png)Tahoe前的RTT估计方式，问题在于估计值r的值没有反应RTT的分布情况，当包的RTT分布情况较密集时（图中a的情况），β为2的估计过于保守，这会导致RTT估计过大，而包的RTT分布较广泛时（图中b曲线、蓝色），β为2的估计过于激进，会导致RTT估计过小

![输入图片说明](/imgs/2025-09-21/Sq8bPeuWFGTGkntN.png)Tahoe通过引入RTT方差的概念来解决这一问题，通过将偏差也平滑之后再进行超时计算，v体现了网络的波动程度，网络波动越大，超时时间估计的越保守

### 自时钟
![输入图片说明](/imgs/2025-10-04/WiR0qrCo8t42x9RH.png)自时钟模型，上图模型展示了发送端和接收端都有一个较大的缓冲区，但是受到链路瓶颈的限制，发送的时间会被拉长，接收端受到后有变回原样，但是由于传输过程中的时间被拉长了，故接收端两个包之间会有时间间隔，发送回的ack也有间隔，同时因为ack的体积更小，会使得链路中有大量的空闲，发送端收到的ack频率也远小于发送频率，而发送端就会根据收到的ack速率调整自己发送数据的速率，这样数据包就可以根据正确的速率进入链路。简单来说，ack除了充当确认信号外，还起到了作为时钟的作用

![输入图片说明](/imgs/2025-10-04/wBlqTY9SaDaYLr2X.png)自时钟原则

### 三大机制总结
![输入图片说明](/imgs/2025-10-04/j08f3wBvLeLKhMHc.png)总的来说，拥塞窗口/慢启动、超时估计、自时钟三个机制是TCP Tahoe的核心基础

## TCP Reno / TCP NewReno
TCP Tahoe的进一步改进，在保证正确性的前提下提高了性能。简单来说，Tahoe在慢启动时指数增长，超时时将窗口阈值改为当前值一半，然后窗口大小改为1，再次慢启动，到达阈值时变为线性增长，直到遇到超时。
![输入图片说明](/imgs/2025-10-20/B1uizAnXH4KYbBm9.png)Tahoe示意图

Reno和Tahoe的区别在于收到三个重复ACK时的行为不同，不再将窗口大小降到1进入慢启动，而是将大小设置为一半，称其为快速恢复，同时不等待三个ACK的超时，而是直接马上重传

![输入图片说明](/imgs/2025-10-20/73Lai2LEd1OLa6SN.png)Reno特点

![输入图片说明](/imgs/2025-10-20/XrZ4zg6R4gHw5EJx.png)Reno示意图
窗口大小降低后的不变的区间是在进行快速重传，遇到超时时和Tahoe的行为相同，进入慢启动在对数时间内回到阈值
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTQzNzIyMjc2NSwxNTgyODQ0ODg3LC00Mj
QxMzI5NywxMjQwOTc1OTcxLC03MzM2MzQzOTgsNTAyOTY1NTU5
LC0zMzAxMzk5NjQsLTE0NTg5MTIwODIsMTg1MjM2MjczNiw2Nz
MxNzgzMDAsLTE1OTA5OTY2MzUsNzU5ODUwMDQyLDE0MjYzOTIw
NjUsLTYwODEyNTYwMiwtNzgzNjkzMTU3LDEyMTU0MDAzMjEsLT
kxNjM3ODgwMywxNzA0Mzk3NzgwLDE3NTk1MTYyOTQsLTY1MTIw
MTkxN119
-->